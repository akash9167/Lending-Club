---
title: "R Notebook - Assignment 1A : Lending Club case"
author: "Akash Bunde (665383604)"
date: "Sept 18, 2021"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.

```{r}
library(tidyverse)
library(lubridate)
library(ROCR)
library(data.table)
library(expss)
library(ggplot2)
library(cowplot)
library(ranger)
library(dplyr)
library(splitstackshape)
library(caret)
library(rpart)
library(ranger)
library(base)
library(libcoin)
library(C50)


```

The lcData100K.csv file contains a sample of data on 3-year loans which we will use for this analyses

```{r}

lcdf <- read_csv('lcdata100K/lcData100K.csv')

```

\#Q2. Exploring the data

(i) What is the proportion of defaults ('charged off' vs 'fully paid' loans) in the data? How does default rate vary with loan grade? Does it vary with sub-grade? And is this what you would expect, and why?

```{r}
# Overall
lcdf %>% summarise(defaultRate=round(sum(loan_status=="Charged Off")*100/n()), paidRate=round(sum(loan_status=="Fully Paid")*100/n()))

# By Grade
defGradeDf <- lcdf %>% group_by(grade) %>% summarise(defaultRate=round(sum(loan_status=="Charged Off")*100/n()), paidRate=round(sum(loan_status=="Fully Paid")*100/n()))

# By Sub-Grade
defSgradeDf <- lcdf %>% group_by(sub_grade) %>% summarise(defaultRate=round(sum(loan_status=="Charged Off")*100/n()), paidRate=round(sum(loan_status=="Fully Paid")*100/n()))

ggplot(defGradeDf, aes( x = grade, y = defaultRate, group = 1)) + geom_line()
ggsave(filename = 'defGradePlot', width = 5, height = 3, device='tiff', dpi=300)

ggplot(defSgradeDf, aes( x = sub_grade, y = defaultRate, group = 1)) + geom_line() + theme(text = element_text(size=7))
ggsave(filename = 'defSGradePlot', width = 5, height = 3, device='tiff', dpi=300)
```

(ii) How many loans are there in each grade? And do loan amounts vary by grade? Does interest rate for loans vary with grade, subgrade? Look at the average, standard-deviation, min and max of interest rate by grade and subgrade. Is this what you expect, and why?

```{r}
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), stdInterest=sd(int_rate), minInterest=min(int_rate), maxInterest=max(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))


lcdf %>% group_by(sub_grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), stdInterest=sd(int_rate), minInterest=min(int_rate), maxInterest=max(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))
```

(iii) For loans which are fully paid back, how does the time-to-full-payoff vary? For this, calculate the 'actual term' (issue-date to last-payment-date) for all loans. How does this actual-term vary by loan grade (a box-plot can help visualize this)

```{r}
head(lcdf[, c("last_pymnt_d", "issue_d")])

lcdf$last_pymnt_d_new<-paste(lcdf$last_pymnt_d, "-01", sep = "")
#     Then convert this character to a date type variable
lcdf$last_pymnt_d_new<-parse_date_time(lcdf$last_pymnt_d_new,  "myd")

#Check their format now
head(lcdf[, c("last_pymnt_d_new", "issue_d")])


lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d_new)/dyears(1), 3)

lcdf %>% group_by(grade) %>% summarise(avgTerm= mean(actualTerm), stdInterest=sd(actualTerm), minInterest=min(actualTerm), maxInterest=max(actualTerm), median(actualTerm))

lcdf %>% filter(loan_status=="Fully Paid") %>% ggplot( aes( x = grade, y = actualTerm)) + geom_boxplot()
```

(iv) Calculate the annual return. Show how you calculate the percentage annual return. Is there any return from loans which are 'charged off'? Explain. How does return from charged - off loans vary by loan grade? Compare the average return values with the average interest_rate on loans -- do you notice any differences, and how do you explain this? How do returns vary by grade, and by sub-grade. If you wanted to invest in loans based on this data exploration, which loans would you invest in?

```{r}
lcdf$annualRet <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

  
lcdf %>% group_by(loan_status, grade) %>% summarise(avgRet=mean(annualRet) ,avgInt=mean(int_rate))


lcdf %>% group_by(loan_status, sub_grade) %>% summarise(avgRet=mean(annualRet), avgInt=mean(int_rate))
```

(v)What are people borrowing money for (purpose)? Examine how many loans, average amounts, etc. by purpose? Do loan amounts vary by purpose? Do defaults vary by purpose? Does loan-grade assigned by Lending Club vary by purpose?

```{r}
lcdf %>% group_by(purpose) %>% tally()

purposeDf <- lcdf %>% group_by(purpose) %>% summarise(nLoans=n(),  avgLoanAmt=mean(loan_amnt), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgAnnualRet = mean(annualRet), avgActTerm=mean(actualTerm))

purposeDf

ggplot(purposeDf, aes(x=purpose, y=defaultRate, group=1)) + geom_line() + theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1) )

lcdf$count <- 1

```

```{r}

purposeGradeDf <- lcdf[,c("purpose", "grade", "count")] %>% pivot_wider(names_from = grade, values_from = count, values_fn = sum, values_fill = 0)

purposeGradeDf<-purposeGradeDf %>% remove_rownames %>% column_to_rownames(var="purpose")

 purposeGradeDf <- prop_col(purposeGradeDf)

purposeGradeDf <- tibble::rownames_to_column(purposeGradeDf, "purpose")

#view(purposeGradeDf)

purposeGradeDf<-purposeGradeDf %>% 
  pivot_longer(!purpose, names_to = "Grade", values_to = "count1")

purposeGradeDf<-data.frame(purposeGradeDf)

ggplot(purposeGradeDf, aes(fill=Grade, y=count1, x=purpose)) + 
    geom_bar(position="dodge", stat="identity")+ theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1) )

purpPropGrade<-prop_col(purposeGradeDf)

```

(vi) Consider some borrower characteristics like employment-length, annual-income, fico-scores (low, high). How do these relate to loan attribute like, for example, loan_amout, loan_status, grade, purpose, actual return, etc.

```{r}
# Relationship of Employment length with Loan various Attributes.
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100
lcdf%>% group_by(emp_length)%>% summarise(avg_loan= mean(loan_amnt))
lcdf%>% group_by(emp_length)%>% summarise(avg_ret= mean(annRet))
lcdf%>% group_by(emp_length)%>% summarise(loan_status )
lcdf%>% group_by(emp_length)%>% summarise(grade )
table( lcdf$purpose, lcdf$emp_length)

# Relatiship of Annual Income of the Lender with Loan various Attributes.
lcdf%>% group_by(annual_inc)%>% summarise(avg_loan= mean(loan_amnt))
lcdf%>% group_by(annual_inc)%>% summarise(avg_ret= mean(annRet))
lcdf%>% group_by(annual_inc)%>% summarise(loan_status )


#reference below is the graph drawn showing the realtion of employment length with Purpose
lcdf$count <- 1
purposeempDf <- lcdf[,c("emp_length", "purpose", "count")] %>% pivot_wider(names_from = purpose, values_from = count, values_fn = sum, values_fill = 0)

purposeempDf<-purposeempDf %>% remove_rownames %>% column_to_rownames(var="emp_length")

purposeempDf <- prop_col(purposeempDf)

purposeempDf <- tibble::rownames_to_column(purposeempDf, "emp_length")

#view(purposeempDf)

purposeempDf<-purposeempDf %>% 
  pivot_longer(!emp_length, names_to = "purpose", values_to = "count1")

purposeempDf<-data.frame(purposeempDf)

ggplot(purposeempDf, aes(fill=purpose, y=count1, x=emp_length)) + 
    geom_bar(position="dodge", stat="identity")+ theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1) )

purpPropemp<-prop_col(purposeempDf)

##reference below is the graph drawn showing the realtion of employment length with Grade
empGradeDf <- lcdf[,c("emp_length", "grade", "count")] %>% pivot_wider(names_from = grade, values_from = count, values_fn = sum, values_fill = 0)

empGradeDf<-empGradeDf %>% remove_rownames %>% column_to_rownames(var="emp_length")

 empGradeDf <- prop_col(empGradeDf)

empGradeDf <- tibble::rownames_to_column(empGradeDf, "emp_length")

#view(employmentlengthgrade Df)

empGradeDf<-empGradeDf %>% 
  pivot_longer(!emp_length, names_to = "grade", values_to = "count1")

empGradeDf<-data.frame(empGradeDf)

ggplot(empGradeDf, aes(fill=grade, y=count1, x=emp_length)) + 
    geom_bar(position="dodge", stat="identity")+ theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1) )

purpPropGrade<-prop_col(purposeGradeDf)

```

(c) Are there missing values? What is the proportion of missing values in different variables? Explain how you will handle missing values for different variables. You should consider what he variable is about, and what missing values may arise from -- for example, a variable monthsSinceLastDeliquency may have no value for someone who has not yet had a delinquency; what is a sensible value to replace the missing values in this case? Are there some variables you will exclude from your model due to missing values?

```{r}
# seeing missing values proportions
names(lcdf)[colSums(is.na(lcdf))>0]
# filled value  proportions
names(lcdf)[colSums(!is.na(lcdf))>0]
colMeans(is.na(lcdf)) #proportion of na

#for seeing the data in excel, we are converting the data to data frame
data.frame(colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0])
write.csv(x=data.frame(colMeans(is.na(lcdf))), file="naproportion.csv")


#Removing columns with all empty rows
lcdf <- lcdf %>% subset(select = c(names(lcdf)[colSums(!is.na(lcdf))>0]))

# Types of Handling the Missing values:
#1. For the variables with data margins is small and cannot be zero, we can prevent information loss by replacing the missing value with Median. Here missing values in number of revolving accounts and Months since most recent 90 day or worst rating can be replaced with median because 99% and 76% are filled and none of them are zero.
#2. For Variables which have values only when an event occurs, the missing values can be safely assumed as zero because missing values may have caused due to the non occurance event. some such variables are Months since last inquiry, Months since recent Bankcard.
#3. Some missing values cannot be replaced. but we cannot leave them as the outputs in some forms cannot show the existance of missing values and causes misinterpretation of the data. So we fill them with a fixed charecter or string to denote the missing value. here we used the string "missing"


lcdf<- lcdf %>% replace_na(list(num_rev_accts=median(lcdf$num_rev_accts, na.rm=TRUE)
                                , revol_util=median(lcdf$revol_util,na.rm=TRUE)
                                ,hardship_dpd= median(lcdf$hardship_dpd, na.rm=TRUE)
                                ,settlement_term= median(lcdf$settlement_term, na.rm=TRUE)
                                ,il_util=median(lcdf$il_util, na.rm=TRUE)
                                ,max_bal_bc=median(lcdf$max_bal_bc, na.rm=TRUE)
                                ,all_util=median(lcdf$all_util, na.rm=TRUE)
                                ,inq_fi=median(lcdf$inq_fi, na.rm=TRUE)
                                ,total_cu_tl=median(lcdf$total_cu_tl, na.rm=TRUE)
                                ,bc_util=median(lcdf$bc_util, na.rm=TRUE)
                                ,bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE)
                                ,avg_cur_bal=median(lcdf$avg_cur_bal, na.rm=TRUE)
                                ,pct_tl_nvr_dlq= 0,mtths_since_recent_bc= 0,mths_since_recent_inq = 0
                                ,open_acc_6m=0, open_act_il=0, open_il_12m=0, open_il_24m=0,total_bal_il=0
                                ,open_rv_12m=0, open_rv_24m=0, inq_last_12m=0, mths_since_last_record=0
                                ,mths_since_recent_bc_dlq=0, mths_since_last_major_derog=0
                                ,mths_since_recent_revol_delinq=0,mths_since_last_delinq=0
                                ,num_tl_120dpd_2m=0, mo_sin_old_il_acct=0,bc_util=0
                                ,percent_bc_gt_75=0, bc_open_to_buy=0, mths_since_rcnt_il=0
                                ,mths_since_recent_bc=0,emp_title="missing"
                                ,purpose= "missing", title="missing" , last_pymnt_d ="missing"))



# We can replace missing values in a variable with
#      replace_na( variable, "value for missing")
table( replace_na( lcdf$open_acc_6m, "missing") )   # shows the 'missing' values


```

4\. Do a univariate analyses to determine which variables (from amongst those you decide to consider for the next stage prediction task) will be individually useful for predicting the dependent variable (loan_status). For this, you need a measure of relationship between the dependent variable and each of the potential predictor variables. Given loan-status as a binary dependent variable, which measure will you use? From your analyses using this measure, which variables do you think will be useful for predicting loan_status? (Note -- if certain variables on their own are highly predictive of the outcome, it is good to ask if this variable has a leakage issue).

```{r}
a <- sapply(lcdf, class)
library(ROCR)
a = names(a)[as.character(a) == "numeric"]
b = sapply(a, function(x) {
  predictions = lcdf[, x][!is.na(lcdf[, x])]
  labels = lcdf[, "loan_status"][!is.na(lcdf[, x])]
  pred <- prediction(predictions, labels)
  performance(pred, "auc")@y.values[[1]]
})

write.csv(data.frame(b), file='AUC.csv')
```

```{r}
#3 new attributes
#Proportion of open revolving accounts
lcdf$prop_act_rev_acc <- lcdf$num_op_rev_tl/lcdf$num_rev_accts

lcdf %>% group_by(loan_status, grade) %>% summarise(avg_act_rev_acc=mean(prop_act_rev_acc))

#Investors Loss
lcdf$loss <- lcdf$total_pymnt - lcdf$funded_amnt
lcdf %>% group_by(loan_status, grade) %>% summarise(avg_act_rev_acc=mean(loss))

#proportion of amount received
lcdf$prop_amt_rec <- (lcdf$total_rec_int + lcdf$total_rec_late_fee + lcdf$total_rec_prncp) / lcdf$funded_amnt
lcdf %>% group_by(loan_status, grade) %>% summarise(avg_act_rev_acc=mean(prop_amt_rec))
```

Data Cleaning

```{r}
##identifying numeric columns
num_col <- unlist(lapply(lcdf, is.numeric))  
data_num <- lcdf[ , num_col]                      

##identifying character columns
cha_col <- unlist(lapply(lcdf, is.character))
data_cha<- lcdf[ , cha_col]

#converting datatype from character to factor
data_cha <- lapply(data_cha, as.factor)

#combining the two types of columns
nData<-cbind(data_num, data_cha)


data_num = ''
data_cha = ''
 
dim(nData)

##Removing Leakage variables (LR-Leakage removed)
drops <- c("hardship_start_date","hardship_end_date","deferral_term","hardship_amount","hardship_status","hardship_type"
           ,"hardship_reason","sec_app_mths_since_last_major_derog","sec_app_collections_12_mths_ex_med"
           ,"sec_app_chargeoff_within_12_mths","sec_app_num_rev_accts","sec_app_open_act_il","sec_app_revol_util"
           ,"sec_app_open_acc","sec_app_mort_acc","sec_app_inq_last_6mths","sec_app_earliest_cr_line","revol_bal_joint"
           ,"dti_joint","annual_inc_joint","next_pymnt_d","url","desc","orig_projected_additional_accrued_interest"
           ,"payment_plan_start_date","settlement_status","settlement_amount","hardship_payoff_balance_amount"
           ,"hardship_loan_status","hardship_length","settlement_percentage","debt_settlement_flag_date"
           ,"hardship_last_payment_amount","id", "member_id","recoveries", "collection_recovery_fee", "last_credit_pull_d"
           ,"debt_settlement_flag","total_rec_prncp", "total_pymnt"
           ,"total_pymnt_inv","total_rec_int","issue_d","last_pymnt_amnt"
           ,"last_pymnt_d", "total_rec_late_fee","funded_amnt", "installment", 'actualTerm', 'annualRet', 'prop_amt_rec'
           , 'loss', 'prop_act_rev_acc', 'funded_amnt_inv', 'dti', 'dti_joint', 'annRet', 'avg_cur_bal'
           ,'bc_util', 'tot_cur_bal', 'num_rev_tl_bal_gt_0', 'term')

nDataLR <- nData[ , !(names(nData) %in% drops)]
```
Dividing data into training and test set

```{r}
#setting seed value to get same sample every time for comparison
set.seed(10)

nr=nrow(nDataLR)

trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE) #get a random 70%sample of row-indices

nDataTrn=nDataLR[ trnIndex, ] #training data with the randomly selected row-indices
nDataTst = nDataLR[ -trnIndex, ] #test data with the other row-indices
```

Decision trees (RPart)

```{r}
#Defining loss matrix that penalizes false positives more than false negatives
lossmatrix <- matrix(c(0,4,1,0), byrow = TRUE, nrow = 2)

#rpDT1 <- rpart(loan_status ~ ., data=nDataTrn
#               ,method="class"
#               ,control = rpart.control(cp = 0.0)
#               ,parms = list(loss = lossmatrix, split="information"))


rpDT1 <- rpart(loan_status ~ ., data=nDataTrn
               ,method="class"
               ,control = rpart.control(cp = 0.0)
               ,parms = list(loss = lossmatrix))

#rpart.plot::prp(rpDT1, type=2, extra=1)
#fancyRpartPlot(rpDT1)

trnPred=predict(rpDT1, nDataTrn, type='class')

table( pred = trnPred, true=nDataTrn$loan_status)

mean(trnPred==nDataTrn$loan_status)

head(rpDT1$variable.importance)

write_csv(as_tibble(rpDT1$variable.importance, rownames = "VarNames"), file='dt_var_imp.csv') 

printcp(rpDT1)

plotcp(rpDT1)

```


```{r}
# based on above table chosen cp~0.0001

rpDT1 <- rpart(loan_status ~ ., data=nDataTrn
               ,method="class"
               ,control = rpart.control(cp = 0.0001)
               ,parms = list(loss = lossmatrix))

trnPred=predict(rpDT1, nDataTrn, type='class')

table( pred = trnPred, true=nDataTrn$loan_status)
#accuracy
mean(trnPred==nDataTrn$loan_status)

printcp(rpDT1)

```

Checking model on test data

```{r}
tstPred = predict(rpDT1, nDataTst, type='class')

table(pred = tstPred, true=nDataTst$loan_status)

print('Accuracy on test data is:')
mean(tstPred==nDataTst$loan_status)
```

Classifier performance 

```{r}
# Training Data
predTrnProb=predict(rpDT1, nDataTrn, type='prob')


#Create a data-frame with only the model scores and the actual class (loan_status) values
trnSc <- nDataTrn %>% select("loan_status") # selects the OUTCOME column into trnSc
trnSc$score <- predTrnProb[, 1] # (note: first column has index of 1)


#sort by score
trnSc <- trnSc[ order(trnSc$score, decreasing=TRUE), ]

# generate the cumulative sum of "default" OUTCOME values
trnSc$cumChargedOff<-cumsum(trnSc$loan_status == "Charged Off")

#Plot the cumChargedOff values (y-axis) by numCases (x-axis)
plot.new()
plot( trnSc$cumChargedOff, type = "l", xlab='#cases', ylab='#Charged-off')
abline(0,max(trnSc$cumChargedOff)/70000, col="blue") #diagonal line

# calculating Decile Lift

trnSc <- nDataTrn %>% select("loan_status") # selects the loan_status column into trnSc
trnSc$score <- predTrnProb[, 1]


#To divide the data into 10 (for decile) equal groups, create a new column with group number for each row
trnSc["bucket"] <- ntile( -trnSc[,"score"], 10) 

#group the data by the 'buckets', and obtain summary statistics
buckDf <- trnSc %>% group_by (bucket) %>%
  summarize ( count=n(),
    numChargedOff = sum(loan_status=="Charged Off"),
    defRate = numChargedOff/count,
    cumDefRate = cumsum(numChargedOff)/cumsum(count),
    lift = cumDefRate / (sum(trnSc$loan_status=="Charged Off")/nrow(trnSc)))

buckDf


#obtain the scores from the model for the class of interest, here, the prob('default')
scoreTrn <- predict(rpDT1, nDataTrn, type="prob")[ ,'Charged Off'] 

#now apply the prediction function from ROCR to get a prediction object
rocPredTrn <- prediction(scoreTrn, nDataTrn$loan_status, label.ordering = c('Fully Paid', 'Charged Off')) 

#obtain performance using the function from ROCR, then plot
perfROCTrn <- performance(rocPredTrn, "tpr", "fpr")

plot(perfROCTrn)


#AUC value
aucPerf=performance(rocPredTrn, "auc")
aucPerf@y.values

#Accuracy
accPerf <-performance(rocPredTrn, "acc")
plot(accPerf)

#optimal threshold for max overall accuracy
accPerf@x.values[[1]][which.max(accPerf@y.values[[1]])]

#optimal cost with different costs for fp and fn
costPerf = performance(rocPredTrn, "cost", cost.fp = 1, cost.fn = 3)
costPerf@x.values[[1]][which.min(costPerf@y.values[[1]])]

#Lift curve
liftPerf <-performance(rocPredTrn, "lift", "rpp")
plot(liftPerf)
```

```{r}
# Test Data

predTstProb=predict(rpDT1, nDataTst, type='prob')


#Create a data-frame with only the model scores and the actual class (loan_status) values
tstSc <- nDataTst %>% select("loan_status") # selects the OUTCOME column into trnSc
tstSc$score <- predTstProb[, 1] # (note: first column has index of 1)


#sort by score
tstSc <- tstSc[ order(tstSc$score, decreasing=TRUE), ]

# generate the cumulative sum of "default" OUTCOME values
tstSc$cumChargedOff<-cumsum(tstSc$loan_status == "Charged Off")

#Plot the cumChargedOff values (y-axis) by numCases (x-axis)
plot.new()
plot( tstSc$cumChargedOff, type = "l", xlab='#cases', ylab='#Charged-off')
abline(0,max(tstSc$cumChargedOff)/30000, col="blue") #diagonal line

# calculating Decile Lift

tstSc <- nDataTst %>% select("loan_status") # selects the loan_status column into trnSc
tstSc$score <- predTstProb[, 1]


#To divide the data into 10 (for decile) equal groups, create a new column with group number for each row
tstSc["bucket"] <- ntile( -tstSc[,"score"], 10) 

#group the data by the 'buckets', and obtain summary statistics
buckDf <- tstSc %>% group_by (bucket) %>%
  summarize ( count=n(),
    numChargedOff = sum(loan_status=="Charged Off"),
    defRate = numChargedOff/count,
    cumDefRate = cumsum(numChargedOff)/cumsum(count),
    lift = cumDefRate / (sum(trnSc$loan_status=="Charged Off")/nrow(tstSc)))

buckDf


#obtain the scores from the model for the class of interest, here, the prob('default')
scoreTst <- predict(rpDT1, nDataTst, type="prob")[ ,'Charged Off'] 

#now apply the prediction function from ROCR to get a prediction object
rocPredTst <- prediction(scoreTst, nDataTst$loan_status, label.ordering = c('Fully Paid', 'Charged Off')) 

#obtain performance using the function from ROCR, then plot
perfROCTst <- performance(rocPredTst, "tpr", "fpr")

plot(perfROCTst)

#AUC value
aucPerf=performance(rocPredTst, "auc")
aucPerf@y.values

#Accuracy
accPerf <-performance(rocPredTst, "acc")
plot(accPerf)

#optimal threshold for max overall accuracy
accPerf@x.values[[1]][which.max(accPerf@y.values[[1]])]

#optimal cost with different costs for fp and fn
costPerf = performance(rocPredTst, "cost", cost.fp = 1, cost.fn = 3)
costPerf@x.values[[1]][which.min(costPerf@y.values[[1]])]

#Lift curve
liftPerf <-performance(rocPredTst, "lift", "rpp")
plot(liftPerf)

```

Using C50 for decision trees

```{r}
c5_DT1 <- C5.0(loan_status ~ ., data=subset(nDataTrn, select = -c(emp_title, title, pymnt_plan,out_prncp,out_prncp_inv,policy_code,count,pymnt_plan,hardship_flag, disbursement_method) ), control=C5.0Control(minCases=10, CF=0.5))

glimpse(nDataTrn)

summary(c5_DT1)

predTstProb_c5dt1 <- predict(c5_DT1, nDataTst, type='prob')


#Performance - test
nDatapredTst = ifelse(predTstProb_c5dt1[, 'Charged Off'] >= 0.5, 'Charged Off', 'Fully Paid')

table( pred = nDatapredTst, true=nDataTst$loan_status)
#Accuracy
mean(nDatapredTst==nDataTst$loan_status)


```

RANDOM FOREST


```{r}
# Using Ranger package for Random forest implementation

model <- ranger(loan_status~., data=nDataTrn, num.trees = 100, importance='permutation',
                probability = TRUE, mtry=50)

# Variable importance
vimpR<- ranger::importance(model)

write_csv(as_tibble(vimpR, rownames = "VarNames"), file='rf_var_imp.csv')

```


Classifier Performance
```{r}

#prediction of Testing Data
predTst <- predict(model,nDataTst)

g#Obtain the model's predictions on the training data
predTrn<- predict(model, nDataTrn)

#predTrn$predictions
CTHRESH = 0.5
predTrnClass = ifelse(predTrn$predictions[, 'Charged Off'] >= CTHRESH, 'Charged Off', 'Fully Paid')
predTstClass = ifelse(predTst$predictions[, 'Charged Off'] >= CTHRESH, 'Charged Off', 'Fully Paid')


#Confusion table of Training data
table(pred = predTrnClass, true=nDataTrn$loan_status)

########################## update as above ###########################
#Confusion table of Testing data
table(pred = predTstClass, true=nDataTst$loan_status)


#confusionMatrix(predTrnClass, reference = nDataTrn$loan_status)

#Accuracies of Training and test data
mean(predTrnClass == nDataTrn$loan_status)
mean(predTstClass == nDataTst$loan_status)


```
ROC curve OF Training Data

```{r}


#ROCR.simple$predictions
#ROCR.simple$labels

nDataTrn$loan_status_changed <- ifelse(nDataTrn$loan_status == "Charged Off",1,0)

#now apply the prediction function from ROCR to get a prediction object
rocPredTrn <- prediction(predTrn$predictions[, 'Charged Off'] , nDataTrn$loan_status_changed)


#obtain performance using the function from ROCR, then plot
perfROCTst <- performance(rocPredTrn, "tpr", "fpr")
plot(perfROCTst)

#AUC 

aucPerf=performance(rocPredTrn, "auc")
aucPerf@y.values
```

ROC curve of Test Data

```{r}
nDataTst$loan_status_changed <- ifelse(nDataTst$loan_status == "Charged Off",1,0)

#now apply the prediction function from ROCR to get a prediction object
rocPredTst <- prediction(predTst$predictions[, 'Charged Off'] , nDataTst$loan_status_changed)


#obtain performance using the function from ROCR, then plot
perfROCTst <- performance(rocPredTst, "tpr", "fpr")
plot(perfROCTst)

#AUC 

aucPerf=performance(rocPredTst, "auc")
aucPerf@y.values

```


Lift curve of Training Data

```{r}

#Create a data-frame with only the model scores and the actual class (OUTCOME) values
trnSc <- nDataTrn %>% select("loan_status") # selects the OUTCOME column into trnSc
trnSc$score <- predTrn$predictions [, 1] # (note: first column has index of 1)
trnSc
#sort by score
trnSc <- trnSc[ order(trnSc$score, decreasing=TRUE), ]
head(trnSc)
# generate the cumulative sum of "Charged off" loan_status values

trnSc$cumchargedoff<- cumsum(trnSc$loan_status == "Charged Off")

head(trnSc)
#Plot the cumchargedoff values (y-axis) by numCases (x-axis)
plot( trnSc$cumchargedoff, type = "l", xlab='#cases', ylab='#chargedoff')
abline(0,max(trnSc$cumchargedoff)/4228, col="blue") #diagonal line
```

Lift Curve of Test data

```{r}
#Create a data-frame with only the model scores and the actual class (OUTCOME) values
tstSc <- nDataTst %>% select("loan_status") # selects the OUTCOME column into trnSc
tstSc$score <- predTst$predictions [, 1] # (note: first column has index of 1)
tstSc
#sort by score
tstSc <- tstSc[ order(tstSc$score, decreasing=TRUE), ]
head(tstSc)
# generate the cumulative sum of "Charged off" loan_status values

tstSc$cumchargedoff<- cumsum(tstSc$loan_status == "Charged Off")



head(tstSc)
#Plot the cumchargedoff values (y-axis) by numCases (x-axis)
plot( tstSc$cumchargedoff, type = "l", xlab='#cases', ylab='#chargedoff')
abline(0,max(tstSc$cumchargedoff)/4228, col="blue") #diagonal line
```



```{r}
# Summarizing data to get average term, average interest rate and average returns observed
lcdf%>% group_by(loan_status) %>% summarise(avgInt=mean(int_rate),avgActInt= mean(annualRet), avgTerm=mean(actualTerm))


costTest <- subset(nDataTst, select = c(loan_status, loan_amnt))

costTest$pred_status = predTstClass

table(pred=costTest$pred_status, true=costTest$loan_status)

costTest %>% group_by(pred_status, loan_status) %>% summarise(totalLoanAmnt=sum(loan_amnt), avgLoanAmnt=mean(loan_amnt))
```


```{r}
PROFITVAL = 18.82
LOSSVAL = 35.88

predTstClass <- predict(model, nDataTst)$predictions[,"Fully Paid"]

prPerfRF<-data.frame(predTstClass)

prPerfRF<-cbind(prPerfRF, status=nDataTst$loan_status)

prPerfRF<-prPerfRF[order(-predTstClass) ,]

prPerfRF$profit<-ifelse(prPerfRF$status== 'Fully Paid', PROFITVAL, LOSSVAL)

prPerfRF$cumProfit<-cumsum(prPerfRF$profit)

max(prPerfRF$cumProfit)

prPerfRF$cumProfit[which.max(prPerfRF$cumProfit)]

prPerfRF
```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


```
